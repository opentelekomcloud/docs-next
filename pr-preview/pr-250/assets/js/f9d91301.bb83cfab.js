"use strict";(self.webpackChunkdocs_next=self.webpackChunkdocs_next||[]).push([[44736],{12777:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>c,contentTitle:()=>o,default:()=>h,frontMatter:()=>a,metadata:()=>r,toc:()=>l});const r=JSON.parse('{"id":"best-practices/application-services/distributed-message-service/migrating-kafka-services","title":"Migrating Kafka Services","description":"This solution will demonstrate how you can migrate Kafka services to connect message producers and consumers to a new Kafka instance and can even migrate persisted message data to a new Kafka instance.","source":"@site/docs/best-practices/application-services/distributed-message-service/migrating-kafka-services.md","sourceDirName":"best-practices/application-services/distributed-message-service","slug":"/best-practices/application-services/distributed-message-service/migrating-kafka-services","permalink":"/docs-next/pr-preview/pr-250/docs/best-practices/application-services/distributed-message-service/migrating-kafka-services","draft":false,"unlisted":false,"editUrl":"https://github.com/opentelekomcloud/docs-next/tree/main/docs/best-practices/application-services/distributed-message-service/migrating-kafka-services.md","tags":[{"inline":true,"label":"kafka","permalink":"/docs-next/pr-preview/pr-250/docs/tags/kafka"},{"inline":true,"label":"mirror-maker","permalink":"/docs-next/pr-preview/pr-250/docs/tags/mirror-maker"},{"inline":true,"label":"migration","permalink":"/docs-next/pr-preview/pr-250/docs/tags/migration"},{"inline":true,"label":"dms","permalink":"/docs-next/pr-preview/pr-250/docs/tags/dms"}],"version":"current","frontMatter":{"id":"migrating-kafka-services","title":"Migrating Kafka Services","tags":["kafka","mirror-maker","migration","dms"]},"sidebar":"bestPracticesSidebar","previous":{"title":"Selectively Exposing CCE Workloads with a Dedicated Gateway","permalink":"/docs-next/pr-preview/pr-250/docs/best-practices/application-services/api-gateway/selectively-exposing-cce-workloads-with-a-dedicated-gateway"},"next":{"title":"Improving Kafka Message Processing Efficiency","permalink":"/docs-next/pr-preview/pr-250/docs/best-practices/application-services/distributed-message-service/improving-kafka-message-processing-efficiency"}}');var i=t(74848),s=t(28453);const a={id:"migrating-kafka-services",title:"Migrating Kafka Services",tags:["kafka","mirror-maker","migration","dms"]},o="Migrating Kafka Services",c={},l=[{value:"Prerequisites",id:"prerequisites",level:2},{value:"Migration Scheme 1: Migrating the Production First",id:"migration-scheme-1-migrating-the-production-first",level:2},{value:"Migration Scheme 2: Migrating the Production Later",id:"migration-scheme-2-migrating-the-production-later",level:2},{value:"How Do I Migrate Persisted Data Along with Services?",id:"how-do-i-migrate-persisted-data-along-with-services",level:2},{value:"Using MirrorMaker to Synchronize Data Across Clusters",id:"using-mirrormaker-to-synchronize-data-across-clusters",level:2},{value:"Solution Design",id:"solution-design",level:3},{value:"Installing and Configuring MirrorMaker",id:"installing-and-configuring-mirrormaker",level:3},{value:"MirrorMaker Configuration Properties",id:"mirrormaker-configuration-properties",level:3},{value:"Verifying Data Synchronization",id:"verifying-data-synchronization",level:3}];function d(e){const n={a:"a",admonition:"admonition",code:"code",em:"em",h1:"h1",h2:"h2",h3:"h3",header:"header",img:"img",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,s.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(n.header,{children:(0,i.jsx)(n.h1,{id:"migrating-kafka-services",children:"Migrating Kafka Services"})}),"\n",(0,i.jsx)(n.p,{children:"This solution will demonstrate how you can migrate Kafka services to connect message producers and consumers to a new Kafka instance and can even migrate persisted message data to a new Kafka instance."}),"\n",(0,i.jsx)(n.p,{children:"Kafka services can be migrated in the following two scenarios:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsx)(n.p,{children:"Migrating services to the cloud without downtime"}),"\n",(0,i.jsx)(n.p,{children:"Services that have high requirements on continuity must be smoothly\nmigrated to the cloud because they cannot afford a long downtime."}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsx)(n.p,{children:"Re-deploying services in the cloud"}),"\n",(0,i.jsx)(n.p,{children:"A Kafka instance deployed within an AZ is not capable of cross-AZ\ndisaster recovery. For higher reliability, you can re-deploy\nservices to an instance that is deployed across AZs."}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"prerequisites",children:"Prerequisites"}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsx)(n.p,{children:"Configure the network environment."}),"\n",(0,i.jsx)(n.p,{children:"A Kafka instance can be accessed within a VPC or over a public\nnetwork. For public network access, the producer and consumer must\nhave public access permissions, and the following security group\nrules must be configured:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Inbound"}),": ",(0,i.jsx)(n.code,{children:"TCP/9094"}),", ",(0,i.jsx)(n.code,{children:"0.0.0.0/0"})," -> Access Kafka through the public network (",(0,i.jsx)(n.strong,{children:"without"})," SSL encryption)"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Inbound"}),": ",(0,i.jsx)(n.code,{children:"TCP/9095"}),", ",(0,i.jsx)(n.code,{children:"0.0.0.0/0"})," -> Access Kafka through the public network (",(0,i.jsx)(n.strong,{children:"with"})," SSL encryption)"]}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsx)(n.p,{children:"Create a Kafka instance."}),"\n",(0,i.jsxs)(n.p,{children:["The specifications of the new instance cannot be lower than the\noriginal specifications. For details, see ",(0,i.jsx)(n.a,{href:"https://docs.otc.t-systems.com/distributed-message-service/umn/creating_an_instance.html",children:"Creating an Instance"}),"."]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsx)(n.p,{children:"Create a topic."}),"\n",(0,i.jsxs)(n.p,{children:["Create a topic with the same configurations as the original Kafka\ninstance, including the topic name, number of replicas, number of\npartitions, message aging time, and whether to enable synchronous\nreplication and flushing. For details, see ",(0,i.jsx)(n.a,{href:"https://docs.otc.t-systems.com/cloud-eye/umn/using_the_alarm_function/creating_alarm_notification_topics/creating_a_topic.html",children:"Creating a Topic"}),"."]}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"migration-scheme-1-migrating-the-production-first",children:"Migration Scheme 1: Migrating the Production First"}),"\n",(0,i.jsx)(n.p,{children:"Migrate the message production service to the new Kafka instance. After\nmigration, the original Kafka instance will no longer produce messages.\nAfter all messages of the original Kafka instance are consumed, migrate\nthe message consumption service to the new Kafka instance to consume\nmessages of this instance."}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsx)(n.li,{children:"Change the Kafka connection address of the producer to that of the\nnew Kafka instance."}),"\n",(0,i.jsx)(n.li,{children:"Restart the production service so that the producer can send new\nmessages to the new Kafka instance."}),"\n",(0,i.jsx)(n.li,{children:"Check the consumption progress of each consumer group in the\noriginal Kafka instance until all data in the original Kafka\ninstance is consumed."}),"\n",(0,i.jsx)(n.li,{children:"Change the Kafka connection addresses of the consumers to that of\nthe new Kafka instance."}),"\n",(0,i.jsx)(n.li,{children:"Restart the consumption service so that consumers can consume\nmessages from the new Kafka instance."}),"\n",(0,i.jsx)(n.li,{children:"Check whether consumers consume messages properly from the new Kafka\ninstance."}),"\n",(0,i.jsx)(n.li,{children:"The migration is completed."}),"\n"]}),"\n",(0,i.jsxs)(n.p,{children:["This is a common migration scheme. It is simple and easy to control on\nthe service side. During the migration, the message sequence is ensured,\nso this scheme is ",(0,i.jsx)(n.strong,{children:"suitable for scenarios with strict requirements on\nthe message sequence"}),". However, latency may occur because there is a\nperiod when you have to wait for all data to be consumed."]}),"\n",(0,i.jsx)(n.h2,{id:"migration-scheme-2-migrating-the-production-later",children:"Migration Scheme 2: Migrating the Production Later"}),"\n",(0,i.jsx)(n.p,{children:"Use multiple consumers for the consumption service. Some consume\nmessages from the original Kafka instance, and others consume messages\nfrom the new Kafka instances. Then, migrate the production service to\nthe new Kafka instance so that all messages can be consumed in time."}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsx)(n.p,{children:"Start new consumer clients, set the Kafka connection addresses to\nthat of the new Kafka instance, and consume data from the new Kafka\ninstance."}),"\n",(0,i.jsx)(n.admonition,{type:"note",children:(0,i.jsx)(n.p,{children:"Original consumer clients must continue running. Messages are\nconsumed from both the original and new Kafka instances."})}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsx)(n.p,{children:"Change the Kafka connection address of the producer to that of the\nnew Kafka instance."}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsx)(n.p,{children:"Restart the producer client to migrate the production service to the\nnew Kafka instance."}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsx)(n.p,{children:"After the production service is migrated, check whether the\nconsumption service connected to the new Kafka instance is normal."}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsx)(n.p,{children:"After all data in the original Kafka is consumed, close the original\nconsumption clients."}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsx)(n.p,{children:"The migration is completed."}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.p,{children:["In this scheme, the migration process is controlled by services. For a\ncertain period of time, the consumption service consumes messages from\nboth the original and new Kafka instances. Before the migration, message\nconsumption from the new Kafka instance has already started, so there is\nno latency. However, early on in the migration, data is consumed from\nboth the original and new Kafka instances, so the messages may not be\nconsumed in the order that they are produced. This scheme is ",(0,i.jsx)(n.strong,{children:"suitable\nfor services that require low latency but do not require strict message\nsequence"}),"."]}),"\n",(0,i.jsx)(n.h2,{id:"how-do-i-migrate-persisted-data-along-with-services",children:"How Do I Migrate Persisted Data Along with Services?"}),"\n",(0,i.jsxs)(n.p,{children:["You can migrate consumed data from the original instance to a new\ninstance by using the open-source tool ",(0,i.jsx)(n.a,{href:"https://github.com/miguecoll/kafka-mirror-maker",children:"MirrorMaker"}),". This\ntool mirrors the original Kafka producer and consumer into new ones and\nmigrates data to the new Kafka instance. For details, see\n",(0,i.jsx)(n.a,{href:"#using-mirrormaker-to-synchronize-data-across-clusters",children:"Using MirrorMaker to Synchronize Data Across Clusters"}),"."]}),"\n",(0,i.jsx)(n.admonition,{type:"note",children:(0,i.jsx)(n.p,{children:"Each Open Telekom Cloud Kafka instance stores data in three\nreplicas. Therefore, the storage space of the new instance should be\nthree times that of the original single-replica message storage."})}),"\n",(0,i.jsx)(n.h2,{id:"using-mirrormaker-to-synchronize-data-across-clusters",children:"Using MirrorMaker to Synchronize Data Across Clusters"}),"\n",(0,i.jsxs)(n.p,{children:["In the following scenarios, ",(0,i.jsx)(n.a,{href:"https://cwiki.apache.org/confluence/pages/viewpage.action?pageId=27846330",children:"MirrorMaker"})," can be used to synchronize data\nbetween different Kafka clusters to ensure the availability and\nreliability of the clusters:"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Backup and disaster recovery: An enterprise has multiple data\ncenters. To prevent service unavailability caused by a fault in one\ndata center, cluster data is synchronously backed up in multiple\ndata centers."}),"\n",(0,i.jsx)(n.li,{children:"Cluster migration: As enterprises migrate services to the cloud,\ndata in on-premises clusters must be synchronized with that in cloud\nclusters to ensure service continuity."}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"solution-design",children:"Solution Design"}),"\n",(0,i.jsxs)(n.p,{children:["MirrorMaker can be used to mirror data from the source cluster to the\ntarget cluster. As shown in figure below,\nin essence, MirrorMaker first consumes data from the source cluster and\nthen produces the consumed data to the target cluster. For more\ninformation about MirrorMaker, see ",(0,i.jsx)(n.a,{href:"https://kafka.apache.org/documentation/?spm=a2c4g.11186623.0.0.c82870aav6G9no#basic_ops_mirror_maker",children:"Mirroring data between\nclusters"}),"."]}),"\n",(0,i.jsx)("center",{children:(0,i.jsx)(n.p,{children:(0,i.jsx)(n.img,{src:"https://arch-assets-dev.obs.eu-de.otc.t-systems.com/static/img/docs/best-practices/application-services/distributed-message-service/en-us_image_0000001348167557.png",alt:"Figure 1 How MirrorMakerworks"})})}),"\n",(0,i.jsx)(n.admonition,{title:"Restrictions",type:"warning",children:(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"The IP addresses and port numbers of the nodes in the source cluster\ncannot be the same as those of the nodes in the target cluster.\nOtherwise, data will be replicated infinitely in a topic."}),"\n",(0,i.jsx)(n.li,{children:"Use MirrorMaker to synchronize data between at least two clusters.\nIf there is only one cluster, data will be replicated infinitely in\na topic."}),"\n"]})}),"\n",(0,i.jsx)(n.h3,{id:"installing-and-configuring-mirrormaker",children:"Installing and Configuring MirrorMaker"}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.p,{children:["Create an ECS that can communicate with the source and target\nclusters. For details, see the ",(0,i.jsx)(n.a,{href:"https://docs.otc.t-systems.com/elastic-cloud-server/index.html",children:"ECS\ndocumentation"}),"."]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.p,{children:["Log in to the ECS, install JDK, and add the following contents to\n",(0,i.jsx)(n.strong,{children:".bash_profile"})," in the home directory to configure the\nenvironment variables ",(0,i.jsx)(n.code,{children:"JAVA\\_HOME"})," and ",(0,i.jsx)(n.code,{children:"PATH"}),". In this command,\n",(0,i.jsx)(n.strong,{children:"/opt/java/jdk1.8.0_151"})," is the JDK installation path. Change it\nto the path where you install JDK."]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"export JAVA_HOME=/opt/java/jdk1.8.0_151\nexport PATH=$JAVA_HOME/bin:$PATH\n"})}),"\n",(0,i.jsxs)(n.p,{children:["Run the ",(0,i.jsx)(n.code,{children:"source .bash\\_profile"})," command for the modification to\ntake effect."]}),"\n",(0,i.jsx)(n.admonition,{type:"note",children:(0,i.jsxs)(n.p,{children:["Use Oracle JDK instead of ECS's default JDK (for example, OpenJDK),\nbecause ECS's default JDK may not be suitable. Obtain Oracle JDK\n1.8.111 or later from ",(0,i.jsx)(n.a,{href:"https://www.oracle.com/java/technologies/downloads/#java8",children:"Oracle's official website"}),"."]})}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsx)(n.p,{children:"Download the binary software package of Kafka 3.3.1."}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"wget https://archive.apache.org/dist/kafka/3.3.1/kafka_2.12-3.3.1.tgz\n"})}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsx)(n.p,{children:"Decompress the binary software package."}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"tar -zxvf kafka_2.12-3.3.1.tgz\n"})}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.p,{children:["Go to the binary software package directory and specify the IP\naddresses and ports of the source and target clusters and other\nparameters in the ",(0,i.jsx)(n.strong,{children:"connect-mirror-maker.properties"})," configuration\nfile in the ",(0,i.jsx)(n.strong,{children:"config"})," directory."]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",metastring:'title="connect-mirror-maker.properties"',children:'# Specify two clusters.\nclusters = A, B\nA.bootstrap.servers = A_host1:A_port, A_host2:A_port, A_host3:A_port\nB.bootstrap.servers = B_host1:B_port, B_host2:B_port, B_host3:B_port\n\n# Specify the data synchronization direction. The data can be synchronized unidirectionally or bidirectionally.\nA->B.enabled = true\n\n# Specify the topics to be synchronized. Regular expressions are supported. By default, all topics are replicated, for example, foo-.*.\nA->B.topics = .*\n\n# If the following two configurations are enabled, clusters A and B replicate data with each other.\n#B->A.enabled = true\n#B->A.topics = .*\n\n# Specify the number of replicas. If multiple topics need to be synchronized and their replica quantities are different, create topics with the same name and replica quantity before starting MirrorMaker.\nreplication.factor=3\n\n# Specify the consumer offset synchronization direction (unidirectionally or bidirectionally).\nA->B.sync.group.offsets.enabled=true\n\n############################# Internal Topic Settings  #############################\n# The replication factor for mm2 internal topics "heartbeats", "B.checkpoints.internal" and\n# "mm2-offset-syncs.B.internal"\n# In the test environment, the value can be 1. In the production environment, it is recommended that the value be greater than 1, for example, 3.\ncheckpoints.topic.replication.factor=3\nheartbeats.topic.replication.factor=3\noffset-syncs.topic.replication.factor=3\n\n# The replication factor for connect internal topics "mm2-configs.B.internal", "mm2-offsets.B.internal" and\n# "mm2-status.B.internal"\n# In the test environment, the value can be 1. In the production environment, it is recommended that the value be greater than 1, for example, 3.\noffset.storage.replication.factor=3\nstatus.storage.replication.factor=3\nconfig.storage.replication.factor=3\n\n# customize as needed\n# replication.policy.separator = _\n# sync.topic.acls.enabled = false\n# emit.heartbeats.interval.seconds = 5\n'})}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsx)(n.p,{children:"In the binary software package directory, start MirrorMaker to\nsynchronize data."}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"./bin/connect-mirror-maker.sh config/connect-mirror-maker.properties\n"})}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsx)(n.p,{children:"(Optional) If a topic is created in the source cluster after\nMirrorMaker has been started, and the topic data needs to be\nsynchronized, restart MirrorMaker."}),"\n",(0,i.jsx)(n.admonition,{type:"note",children:(0,i.jsxs)(n.p,{children:["To periodically synchronize new topics without restarting MirrorMaker.\n",(0,i.jsx)(n.code,{children:"refresh.topics.interval.seconds"})," is mandatory. Other parameters are optional."]})}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"mirrormaker-configuration-properties",children:"MirrorMaker Configuration Properties"}),"\n",(0,i.jsxs)(n.table,{children:[(0,i.jsx)(n.thead,{children:(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.th,{children:"Parameter"}),(0,i.jsx)(n.th,{children:"Default Value"}),(0,i.jsx)(n.th,{children:"Description"})]})}),(0,i.jsxs)(n.tbody,{children:[(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"sync.topic.configs.enabled"}),(0,i.jsx)(n.td,{children:"true"}),(0,i.jsx)(n.td,{children:"Whether to monitor the source cluster for configuration changes."})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"sync.topic.acls.enabled"}),(0,i.jsx)(n.td,{children:"true"}),(0,i.jsx)(n.td,{children:"Whether to monitor the source cluster for ACL changes."})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"emit.heartbeats.enabled"}),(0,i.jsx)(n.td,{children:"true"}),(0,i.jsx)(n.td,{children:"Whether to let the connector send heartbeats periodically."})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"emit.heartbeats.interval.seconds"}),(0,i.jsx)(n.td,{children:"5 seconds"}),(0,i.jsx)(n.td,{children:"Heartbeat frequency."})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"emit.checkpoints.enabled"}),(0,i.jsx)(n.td,{children:"true"}),(0,i.jsx)(n.td,{children:"Whether to let the connector periodically send the consumer offset information."})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"emit.checkpoints.interval.seconds"}),(0,i.jsx)(n.td,{children:"5 seconds"}),(0,i.jsx)(n.td,{children:"Checkpoint frequency."})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"refresh.topics.enabled"}),(0,i.jsx)(n.td,{children:"true"}),(0,i.jsx)(n.td,{children:"Whether to let the connector periodically check for new topics."})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"refresh.topics.interval.seconds"}),(0,i.jsx)(n.td,{children:"5 seconds"}),(0,i.jsx)(n.td,{children:"Frequency of checking for new topics in the source cluster."})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"refresh.groups.enabled"}),(0,i.jsx)(n.td,{children:"true"}),(0,i.jsx)(n.td,{children:"Whether to let the connector periodically check for new consumer groups."})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"refresh.groups.interval.seconds"}),(0,i.jsx)(n.td,{children:"5 seconds"}),(0,i.jsx)(n.td,{children:"Frequency of checking for new consumer groups in the source cluster."})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"replication.policy.class"}),(0,i.jsx)(n.td,{children:"org.apache.kafka.connect.mirror.DefaultReplicationPolicy"}),(0,i.jsx)(n.td,{children:"Use LegacyReplicationPolicy to imitate MirrorMaker of an earlier version."})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"heartbeats.topic.retention.ms"}),(0,i.jsx)(n.td,{children:"One day"}),(0,i.jsx)(n.td,{children:"Used when heartbeat topics are created for the first time."})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"checkpoints.topic.retention.ms"}),(0,i.jsx)(n.td,{children:"One day"}),(0,i.jsx)(n.td,{children:"Used when checkpoint topics are created for the first time."})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"offset.syncs.topic.retention.ms"}),(0,i.jsx)(n.td,{children:"max long"}),(0,i.jsx)(n.td,{children:"Used when offset sync topics are created for the first time."})]})]})]}),"\n",(0,i.jsx)(n.h3,{id:"verifying-data-synchronization",children:"Verifying Data Synchronization"}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsx)(n.p,{children:"View the topic list in the target cluster to check whether there are\nsource topics."}),"\n",(0,i.jsx)(n.admonition,{type:"note",children:(0,i.jsxs)(n.p,{children:["Topic names in the target cluster have a prefix (for example,\n",(0,i.jsx)(n.code,{children:"A."}),") added to the source topic name. This is a MirrorMaker 2\nconfiguration for preventing cyclic topic backup."]})}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsx)(n.p,{children:"Produce and consume messages in the source cluster, view the\nconsumption progress in the target cluster, and check whether data\nhas been synchronized from the source cluster to the target cluster."}),"\n",(0,i.jsxs)(n.p,{children:["If the target cluster is a Open Telekom Cloud Kafka instance, view\nthe consumption progress on the ",(0,i.jsx)(n.em,{children:"Consumer Groups"})," page."]}),"\n"]}),"\n"]})]})}function h(e={}){const{wrapper:n}={...(0,s.R)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(d,{...e})}):d(e)}},28453:(e,n,t)=>{t.d(n,{R:()=>a,x:()=>o});var r=t(96540);const i={},s=r.createContext(i);function a(e){const n=r.useContext(s);return r.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:a(e.components),r.createElement(s.Provider,{value:n},e.children)}}}]);