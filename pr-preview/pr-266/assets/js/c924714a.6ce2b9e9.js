"use strict";(self.webpackChunkdocs_next=self.webpackChunkdocs_next||[]).push([[71108],{35446:e=>{e.exports=JSON.parse('{"tag":{"label":"nvidia-operator","permalink":"/docs-next/pr-preview/pr-266/docs/tags/nvidia-operator","allTagsPath":"/docs-next/pr-preview/pr-266/docs/tags","count":1,"items":[{"id":"blueprints/by-use-case/ai/deploy-the-nvidia-gpu-operator-on-cce","title":"Deploy the NVIDIA GPU Operator on CCE","description":"The NVIDIA GPU Operator is a critical tool for effectively managing GPU resources in Kubernetes clusters. It serves as an abstraction layer over Kubernetes APIs, automating tasks such as dynamic provisioning, driver updates, resource allocation, and optimization for GPU-intensive workloads, thereby simplifying the deployment and management of GPU-accelerated applications. Its functionality extends to dynamic provisioning of GPUs on demand, managing driver updates, optimizing resource allocation for varied workloads, and integrating with monitoring tools for comprehensive insights into GPU usage and health. This guide outlines how to deploy the NVIDIA GPU Operator on CCE cluster. The process involves preparing GPU nodes, installing necessary components, configuring the cluster for GPU support, deploying an application leveraging GPUs, and verifying functionality.","permalink":"/docs-next/pr-preview/pr-266/docs/blueprints/by-use-case/ai/deploy-the-nvidia-gpu-operator-on-cce"}],"unlisted":false}}')}}]);